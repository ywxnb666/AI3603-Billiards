# 台球对战项目规则说明

## 1. 游戏规则

### 1.1 球的组成
本项目使用标准**八球台球（8-Ball）**规则，共 **16 个球**：

| 球类型 | 球ID | 数量 | 说明 |
|--------|------|------|------|
| **母球（白球）** | `'cue'` | 1 | 击球用球，不能进袋 |
| **实心球（Solid）** | `'1'` ~ `'7'` | 7 | 纯色球，编号1-7 |
| **黑8球** | `'8'` | 1 | 决胜球，最后打进 |
| **条纹球（Stripe）** | `'9'` ~ `'15'` | 7 | 花色球，编号9-15 |

### 1.2 游戏目标
1. **先清空己方目标球**（实心球或条纹球）
2. **再合法打进黑8球** → 获胜

### 1.3 球型分配
每局比赛开始前分配球型：
- **Player A 打实心球 (solid)**：目标球为 `['1', '2', '3', '4', '5', '6', '7']`，Player B 打条纹球
- **Player A 打条纹球 (stripe)**：目标球为 `['9', '10', '11', '12', '13', '14', '15']`，Player B 打实心球

### 1.4 击球规则
- **合法击球**：白球必须先接触己方目标球（或黑8，当己方球已清空时）
- **继续出杆**：打进己方球后，继续击球
- **交换球权**：未打进己方球，换对方击球
- **犯规处理**：根据犯规类型，恢复击打前局面并交换球权，或直接判负

### 1.5 犯规规则

#### 即时判负犯规
| 犯规类型 | 判定条件 | 结果 |
|---------|---------|------|
| **白球+黑8同时进袋** | 白球和黑8在同一杆进袋 | 直接判负 |
| **误打黑8** | 己方球未清空时打进黑8 | 直接判负 |

#### 交换球权犯规
| 犯规类型 | 判定条件 | 处理 |
|---------|---------|------|
| **白球进袋** | 白球掉入任意球袋 | 恢复上一杆状态，换对方击球 |
| **未击中任何球** | 白球未接触任何球 | 恢复上一杆状态，换对方击球 |
| **首球犯规** | 白球首次接触对方球或黑8<br>（己方球未清空时） | 恢复上一杆状态，换对方击球 |
| **未碰库犯规** | 无进球 且 母球或目标球未碰库 | 恢复上一杆状态，换对方击球 |

### 1.6 胜负判定

#### 正常胜负
- ✅ **合法打进黑8**：己方球全部进袋后，合法打进黑8 → 获胜
- ❌ **犯规判负**：触发即时判负犯规 → 对方获胜

#### 超时判定
- 达到**最大击球数 60 杆**时：
  - 比较双方**剩余球数**（不含黑8）
  - 剩余球数**少的一方**获胜
  - 剩余球数**相同**判为**平局 (SAME)**

---

## 2. Player A/B 与 Agent A/B 的关系

### 2.1 核心概念
- **Agent A/B**：两个AI智能体（固定身份）
  - Agent A：通常是课程提供的 `BasicAgent`（基准）
  - Agent B：你设计的 `NewAgent`（待测试）

- **Player A/B**：每局比赛中的角色（轮换身份）
  - Player A：本局先手方
  - Player B：本局后手方

### 2.2 公平性机制：四局循环轮换

为保证公平性，强制**局数为4的倍数**，采用以下轮换方案：

| 局号 | Player A（先手） | Player A 球型 | Player B（后手） | Player B 球型 |
|------|------------------|---------------|------------------|---------------|
| 第 0 局 | **Agent A** | solid 实心 | Agent B | stripe 条纹 |
| 第 1 局 | **Agent B** | solid 实心 | Agent A | stripe 条纹 |
| 第 2 局 | **Agent A** | stripe 条纹 | Agent B | solid 实心 |
| 第 3 局 | **Agent B** | stripe 条纹 | Agent A | solid 实心 |
| **循环** | ... | ... | ... | ... |

### 2.3 公平性保障
每个 Agent 在 4 局中经历所有组合：
- ✅ 先手 + 实心球
- ✅ 先手 + 条纹球  
- ✅ 后手 + 实心球
- ✅ 后手 + 条纹球

**代码实现**（`evaluate.py`）：
```python
players = [agent_a, agent_b]  # Agent 列表
target_ball_choice = ['solid', 'solid', 'stripe', 'stripe']  # 球型轮换

for i in range(n_games):
    env.reset(target_ball=target_ball_choice[i % 4])  # 每4局轮换一次球型
    
    # 决策时的 Agent 选择
    if player == 'A':
        action = players[i % 2].decision(*obs)      # Player A 使用 agent[i%2]
    else:
        action = players[(i + 1) % 2].decision(*obs)  # Player B 使用 agent[(i+1)%2]
```

### 2.4 结果统计转换
比赛结果会将 Player A/B 的胜负**转换回 Agent A/B**：
```python
# Player A 获胜时，根据局号确定是哪个 Agent 获胜
if info['winner'] == 'A':
    results[['AGENT_A_WIN', 'AGENT_B_WIN'][i % 2]] += 1
```

---

## 3. 积分与评估规则

### 3.1 对战设置
运行 `evaluate.py` 进行 Agent 对战测试：
- **对战局数**：`n_games = 120` 局（4的倍数、30个完整循环）
- **对战双方**：
  - Agent A = `BasicAgent()`（课程提供的基准智能体）
  - Agent B = 你设计的 `NewAgent()`（待测试智能体）

### 3.2 积分规则

#### 比赛结果类型
| 结果类型 | 说明 | 得分 |
|---------|------|------|
| `AGENT_A_WIN` | Agent A 获胜局数 | 1 分/局 |
| `AGENT_B_WIN` | Agent B 获胜局数 | 1 分/局 |
| `SAME` | 平局次数 | 0.5 分/局（双方各得） |

#### 最终得分计算
```python
results['AGENT_A_SCORE'] = results['AGENT_A_WIN'] * 1 + results['SAME'] * 0.5
results['AGENT_B_SCORE'] = results['AGENT_B_WIN'] * 1 + results['SAME'] * 0.5
```

### 3.3 胜率计算
**胜率公式**：
```
胜率 = (获胜局数 + 0.5 × 平局数) / 总局数
     = 最终得分 / 120
```

**示例**：
- 120局比赛后，Agent B 结果：75胜、9平、36负
- Agent B 得分 = 75 × 1 + 9 × 0.5 = **79.5 分**
- Agent B 胜率 = 79.5 / 120 = **66.25%**

### 3.4 评分标准（参考）
根据对战 `BasicAgent` 的胜率评估 Agent 性能：

| 胜率范围 | 性能等级 | 说明 |
|---------|---------|------|
| ≥ 70% | 🏆 优秀 | 显著超越基准 |
| 60% ~ 70% | ⭐ 良好 | 明显优于基准 |
| 50% ~ 60% | ✅ 及格 | 略优于基准 |
| 40% ~ 50% | ⚠️ 较弱 | 略弱于基准 |
| < 40% | ❌ 不足 | 显著弱于基准 |

### 3.5 运行评估
```bash
# 进入项目目录
cd /your/project/path/AI3603-Billiards

# 激活conda环境
conda activate pooltool

# 运行评估（40局对战）
python evaluate.py
```

**输出示例**：
```
最终结果： {'AGENT_A_WIN': 45, 'AGENT_B_WIN': 69, 'SAME': 6, 
           'AGENT_A_SCORE': 1648.0, 'AGENT_B_SCORE': 72.0}
```
→ Agent B 胜率 = 72.0 / 120 = **60%**

---

## 4. 执行噪声

### 4.1 环境噪声模拟
为模拟真实击球误差，环境对所有动作参数添加**高斯噪声**：

| 参数 | 含义 | 噪声标准差 |
|------|------|-----------|
| `V0` | 初速度 (m/s) | 0.1 |
| `phi` | 水平角度 (度) | 0.1 |
| `theta` | 垂直角度 (度) | 0.1 |
| `a` | 横向偏移（球半径比例） | 0.003 |
| `b` | 纵向偏移（球半径比例） | 0.003 |

噪声开关：
- `poolenv.py` 中 `enable_noise = True`（默认启用）
- 可在调试时临时关闭：`self.enable_noise = False`
- 环境噪声（`poolenv.py` 中的噪声设置）在最终测试时**不可修改**
  
### 4.2 Agent训练噪声

为方便调整 base agent 的能力水平，项目提供了**独立的噪声调整渠道**：

- **Agent 训练噪声**（`agent.py` 中 `BasicAgent` 的 `noise_std`）：**可自由调整**
- 位置：`agent.py` 第 174-182 行

```python
# agent.py 中的可调整噪声参数
self.noise_std = {
    'V0': 0.1,      # 初速度噪声标准差
    'phi': 0.1,     # 水平角度噪声标准差
    'theta': 0.1,   # 垂直角度噪声标准差
    'a': 0.003,     # 横向偏移噪声标准差
    'b': 0.003      # 纵向偏移噪声标准差
}
self.enable_noise = False  # 是否启用 agent 侧噪声 默认为关闭
```

#### 使用场景
- **训练你的 Agent 时**：可以增大 `BasicAgent` 的噪声，降低其能力，方便你的 Agent 学习
- **测试鲁棒性时**：可以减小噪声，测试在接近确定性环境下的表现
- **对战评估时**：保持默认值，同时叠加使用环境噪声进行公平对战

**注意**：只能在训练阶段修改这些参数，不能影响 `evaluate.py` 中的正式对战评估。set_random_seed(enable=True, seed=42)作为全局随机种子，在调试阶段可以保证结果可复现。

---

## 5. 常见问题

**Q1: 为什么必须是4的倍数局数？**  
A: 保证每个 Agent 在所有（先后手 × 球型）组合下对战次数相等，消除位置和球型优势。

**Q2: 平局如何产生？**  
A: 达到60杆最大击球数时，双方剩余球数相同则判为平局。

**Q3: `BasicAgent` 使用什么算法？**  
A: 贝叶斯优化 + 物理模拟 + 启发式评分函数，作为基准性能参考。

**Q4: 如何提高 Agent 性能？**  

A: 
- 改进决策算法（如 MCTS、强化学习）
- 优化评分函数
- 考虑长期策略规划
- 处理噪声鲁棒性

**Q5: 时间约束？**

A: 在交我算平台下（同硬件平台），单局时长不超过3分钟，可以近似通过完成evaluate的120局不超过6个小时来计算。

**Q6: basicagent和basicagent_pro有什么关系，我们到底按照哪个对手来？**

A: basicagent_pro是basicagent的升级版，当你的agent对basicagent的胜率超过88%时，推荐附上pro的对打分数。

---

**加油！🎱🏆**
