# Method I：在线搜索（NewAgent）实现总结（基于当前 agents/new_agent.py）

本文档总结当前 `agents/new_agent.py` 中 `NewAgent` 的“在线搜索 / 在线规划”方法实现思路与关键细节，供直接改写到报告 Method I。

> 核心定位：**不用训练模型**，每回合在当前局面中“生成候选 → 物理仿真评估 → 噪声鲁棒性筛选 → 局部微调 → 安全兜底”。

---

## 1. 问题与约束

- 环境输入：`(balls, my_targets, table)`。
- 连续动作：`(V0, phi, theta, a, b)`。
- 真实执行带噪声：环境会对动作参数加入小高斯扰动，因此**单次仿真高分不等于实战可靠**。
- 规则关键：
  - 清台前黑 8 不可进袋；清台后必须合法打进 8。
  - 必须先击打己方目标球（或仅剩 8 时先击打 8）。
  - 未进球时需要碰库（实现里采用“白球或首碰球碰库”的近似判定）。

---

## 2. 总体框架（decision 主流程）

`NewAgent.decision()` 的决策是两段式：

1. **进攻搜索**：`_find_best_shot()` 先用几何+仿真在“目标球×袋口”组合中找一个最好的基础方案（base_action）。
2. **局部微调**：`_refine_shot_with_simulation()` 对 base_action 做局部随机扰动搜索（30 次），用鲁棒评分选更稳的 refined_action。

若进攻搜索/微调后的鲁棒得分仍偏低（阈值约 -80），则进入：

3. **防守/保底**：`_get_safe_shot()` 生成“能合法首碰且尽量不送命”的安全球；如果安全球仍很差，则尝试 `Kick Shot / Bank Shot`（大力解球策略）。

最后还会再做一次**首球合法性快速验证**，不合法直接切回安全策略。

---

## 3. 候选生成：目标球 × 袋口 + Ghost Ball

### 3.1 袋口位置
- `table.pockets.values()` 取每个袋口中心 `pocket.center`，只用 2D `(x, y)`。

### 3.2 Ghost Ball（瞄准点）
- 对每个 `(target_id, pocket)`：
  - 计算 target→pocket 的方向单位向量。
  - 反推“母球应到达的碰撞点”（ghost ball）
    
    $$ \text{aim\_point} = \text{target} + \hat{d}\cdot(2R) $$

  其中 $\hat{d}$ 是从袋口指向目标球的单位方向，\(R\) 为球半径（实现里 `BALL_RADIUS=0.028575`）。

### 3.3 由几何解得到初始动作
- `phi`：`cue_pos → aim_point` 的方向角（`atan2` 转度数，归一到 `[0, 360)`）。
- `V0`：按 “母球→aim_point” 距离 + “目标球→袋口” 距离 的分段经验式给定，并整体乘上 `POWER_REDUCTION=0.9` 以降低白球进袋风险。
- 初始默认：`theta=0, a=b=0`。

---

## 4. 几何启发式评分（快速筛）

`_evaluate_shot_quality()` 给每个候选一个几何分 `geo_score`，用于减少仿真开销并做综合排序。其主要项：

- 距离惩罚：总距离越大越扣分。
- 切角难度：用 `cue→aim_point` 和 `target→pocket` 的夹角，直球奖励，大角度惩罚。
- 路径遮挡：
  - `cue→aim_point`、`target→pocket` 两段做“线段附近是否有球”的简化检测（阈值约 `2.2R`）。
- 袋口接近奖励：目标球离袋口越近越加分。
- 规则/风险项：
  - 用 `_get_first_contact_ball()` 预测首碰球，不是目标球则大幅惩罚（尤其该打 8 时）。
  - 黑 8 风险：非打 8 时，如果击球路线可能触碰 8 或目标球入袋路线可能带入 8，则额外惩罚。

> 这一步是**启发式剪枝**：并不保证可行，只是减少“明显离谱”的候选进入昂贵的仿真阶段。

---

## 5. 首球预测（用于快速合法性过滤）

`_get_first_contact_ball(cue_pos, phi, balls)`：用纯几何近似预测白球沿 `phi` 射线最先撞到谁。

- 对每颗未进袋球：
  - 计算其在射线方向上的投影距离 `proj`（必须 > 0）。
  - 计算到射线的垂距 `perp_dist`。
  - 若 `perp_dist < 2R`，可发生碰撞；用勾股推算碰撞点距离 `collision_dist = proj - sqrt((2R)^2 - perp_dist^2)`。
- 取 `collision_dist` 最小者作为首碰球。

用途：
- 在进入仿真前就过滤掉明显首球犯规的局部扰动参数，节省仿真预算。
- 在最终决策前再做一次快速验证，避免输出明显非法动作。

---

## 6. 仿真评估与规则对齐评分

### 6.1 物理仿真
- `_simulate_and_evaluate()` 会对 `balls/table` 深拷贝，构造 `pt.System`，设置球杆参数后调用 `simulate_with_timeout()`。
- `simulate_with_timeout()` 在支持 `signal.SIGALRM` 的平台（通常 Unix/Linux）上提供硬超时；在 Windows / 不支持 SIGALRM / 非主线程等情况下会自动**降级为直接 `pt.simulate`**，避免因信号机制不可用导致评测失败。

### 6.2 评分函数：强约束“一票否决” + 强罚犯规

仿真结束后通过 `shot.balls` 的状态变化得到 `new_pocketed`，并解析 `shot.events` 判断首球、碰库等。

主要规则：

- **一票否决（致命错误）**：
  - 白球 + 黑 8 同进：直接 `-10000`。
  - 清台前打进黑 8：直接 `-10000`。
- **高风险错误（强惩罚）**：
  - 白球进袋：`-1000`。
  - 首球犯规：约 `-180`；没碰到任何球：约 `-120`。
  - 未进球且未碰库：约 `-200`。
- **进球收益**：
  - 己方球进袋：每颗 `+100`。
  - 对手球进袋：每颗 `-40`。
- **合法无进球奖励**：`+10`。
- **袋口斥力场**：如果白球最终停在袋口很近（`<1.5R`），额外扣分（最多约 500 级别），以避免“停在袋口边缘下一杆容易 scratch”。

> 该评分设计的意图是：与其追求高风险高回报，不如优先保证合法与避免直接输局事件，从而提高对战胜率。

---

## 7. 鲁棒性评估（噪声蒙特卡洛）

`_evaluate_with_robustness(action)` 是在线搜索方法的关键（风险厌恶）：

- 对同一动作重复多次带噪声仿真（默认 FINAL=10），每次在 `V0/phi/theta/a/b` 上加与环境一致的高斯噪声（`noise_std`）。
- **早停（加速失败候选剔除）**：一旦任意一次出现一票否决级错误（`score <= -5000`），立刻停止剩余采样并判为不可用（返回 `-10000`）。
- 否则用保守聚合：

  $$ \text{robust\_score} = 0.6\,\mathbb{E}[s] + 0.4\,\min(s) $$

- 再对“高风险/中风险错误次数”做额外惩罚（阈值随采样数自适应），进一步抑制不稳定动作。

这一步本质是 **chance constraint / risk-averse**：用 Monte Carlo 近似估计“在执行噪声下的最坏情况”，优先选稳定球。

---

## 8. 组合策略：几何分 + 鲁棒分

在 `_find_best_shot()` 中，对每个 `(target, pocket)`：

- 先算 `geo_score`（快）。
- **两阶段评估（提速关键）**：
  - Stage A：先对候选动作做一次“无噪声单次仿真”快速筛选（`sim_score_fast`），剔除明显离谱/致命候选。
  - Stage B：只对 Top-K（例如 6 个）候选做全量带噪声鲁棒评估（`sim_score`），把仿真预算集中到最有希望的方案上。
- 最终综合：

  $$ \text{total} = 0.3\,\text{geo\_score} + 0.7\,\text{sim\_score} $$

权重设置体现“最终还是以仿真鲁棒性为主”，几何仅作为先验。

---

## 8.1 工程加速改进（2025-12-19 更新）

本次对工作区版本进行了针对性加速，目标是在**不牺牲最终动作评估精度**的前提下降低每回合仿真次数：

- 鲁棒性评估分为两档采样数：
  - `ROBUSTNESS_SAMPLES_SCREEN`（默认 4）：用于搜索/微调阶段快速筛选。
  - `ROBUSTNESS_SAMPLES_FINAL`（默认 10）：用于最终候选复核与输出动作评分，保持最终精度。
- 候选集合只对 Top-K（`ROBUST_TOPK`，默认 6）做 FINAL 级别鲁棒评估。
- 微调阶段先用 SCREEN 级别鲁棒得分挑最佳，再对最佳动作做 FINAL 复核后返回。

这一改动借鉴了“先 cheap 评估筛候选、再重评估确认”的思想，通常能显著减少 total simulation 数量。

---

## 8.2 开球快速策略（2025-12-19 更新）

问题：当 `NewAgent` 作为 Player A 执行**第一杆开球**时，若仍按常规流程跑“候选生成 → Top-K 全量鲁棒 → 微调”，会在开球局面浪费大量仿真时间；而开球动作本身不需要如此精细的在线规划。

解决：在 `NewAgent.decision()` 的开头加入“开球局面检测”，一旦判定为开球，直接走轻量开球策略而不进入完整在线搜索。

### 8.2.1 开球局面检测（`_is_break_state`）

由于环境不会把 `hit_count` 传给 Agent，开球局面只能从几何形态推断。

2025-12-25 更新：将开球检测从“bbox/半径聚类阈值”改为 **“完美三角阵（racked triangle）接触图”判定**，更贴近真实开球摆球：

- 15 颗彩球（1~15）全部仍在台面（未进袋）。
- 统计彩球两两距离中，接近 $2R$（两球相切）的近邻对数量 `close_pairs`（允许 10% 容差）。
  - 5 行三角阵（15球）在理想摆放下会出现大量相切近邻对（量级约 30）。
  - 实现里要求 `close_pairs` 超过阈值（例如 22），并要求多数球至少有 2 个近邻（例如 ≥12 颗球满足）。
- 额外紧凑性约束：彩球整体 bbox 对角线不能过大（避免散开后偶然出现大量“近似 2R”的距离）。
- 白球必须离球堆质心足够远（避免把中局的“局部拥挤”误判为开球）。

以上条件满足时，认为是“完美三角阵开球局面”，直接走轻量开球策略。

### 8.2.2 轻量开球决策（`_break_decision`）

核心思想：只做少量候选、极少评估，但必须强保证“首碰合法”（否则环境直接回滚并交换球权）。

2025-12-25 更新：开球策略加入“优先直线可视己方球”的选择逻辑，避免条纹方/实心方在开球时首碰到对方球：

- 优先在 `my_targets`（排除 8）里找“直线可视”的己方球：
  - 对每个己方球，计算 `phi(cue→ball)`；若 `_get_first_contact_ball(cue, phi)` 正好等于该球，则认为可视。
  - 选择最近的一个可视己方球作为开球首碰目标。
- 若找不到可视己方球，再退化到“瞄准球堆质心 + 小角度扫描”，用 `_get_first_contact_ball()` 找到首碰落在 `my_targets` 的角度兜底。
- 力度候选仍保持常数级（例如 V0=6.0/6.6/7.2，`theta=a=b=0`）。
- 评估方式保持极简：只做一次无噪声仿真筛选/排序，不做带噪声鲁棒评估（开球回合以速度为优先）。

收益：开球从“高仿真预算”降为“常数级小预算”，显著减少开局回合的等待时间。

---

## 8.3 对战 Pro 的稳定性增强（2025-12-25 更新）

在与 `BasicAgentPro`（带噪声仿真 + MCTS）对战时，单步贪心的进攻策略更容易“留甜球”被对手连续清台；同时，若评分函数与环境犯规回滚规则不一致，会误选“仿真看似高分、但环境直接回滚丢球权”的动作。

为提高对 Pro 的胜率，加入两项关键改动：

- **犯规/回滚对齐 PoolEnv**：
  - 对 `NO_HIT`（未碰到任何球）、首碰非法（碰到对手球或清台前先碰 8）、未进球且未碰库（白球或首碰球未碰库）这些情形，直接返回大负分，模拟“环境回滚 + 交换球权”的真实代价。
  - 目的：避免搜索在“环境必回滚”的动作上浪费预算，也避免高估这类动作的收益。
- **对手威胁惩罚（1-step opponent threat）**：
  - 当本杆没有打进己方球、预计会交出球权时，估算对手在下一杆的“最强简单进攻机会”（纯几何近似：直线无遮挡 + 小切角 + 短距离）。
  - 若对手存在明显的直线进球机会，对该动作追加惩罚，从而更偏向“不中也不要送球”的安全选择。

---

## 8.4 性能优化：不降低胜率的加速（2025-12-25 更新）

NewAgent 的主要耗时通常不在 `pt.simulate` 本身，而在于“为每次仿真准备输入”的深拷贝：真实环境中每颗球的 `history` 会很长，`deepcopy(ball)` 会把历史轨迹一并复制，导致每回合大量仿真时显著变慢。

本次实现的工程加速点（不减少仿真次数、不改变评分逻辑，原则上不影响胜率）：

- **球状态轻量复制（避免拷贝 history）**：仿真只需要当前 `state` 与物理参数，构造空 `history/history_cts` 的 Ball 副本，仅对 `state` 做深拷贝。
- **避免每次仿真 deepcopy(table)**：仿真中 table 视为只读，直接复用传入 table（它本身已是环境给 agent 的 deepcopy）。
- **袋口坐标缓存**：同一回合内 `table` 对象不变，缓存 `pocket.center` 的 2D 结果，避免重复遍历。

---

## 9. 局部微调（Local Random Search）

`_refine_shot_with_simulation(base_action)` 做 30 次局部采样：

- `V0`: `±0.5`，再 clip 到 `[1.2, 5.5]`（更保守的速度范围）。
- `phi`: `±4` 度。
- `theta`: 采样 `[0, 12]`，再 clip 到 `[0, 15]`。
- `a,b`: 采样 `[-0.12, 0.12]`。

并且在每次仿真前用 `_get_first_contact_ball()` 做首球合法性快速过滤（不合法直接跳过），从而把仿真预算集中在可能有效的区域。

补充（2025-12-19）：微调阶段使用 SCREEN 级鲁棒评估做筛选，最后对最佳动作做 FINAL 复核后输出，以兼顾速度与精度。

---

## 10. 防守与绝境策略

当进攻搜索失败或得分过低，进入 `_get_safe_shot()`：

- 尝试对每个目标球：
  - 直接瞄准目标球中心（或微调角度绕障）。
  - 速度设为能确保碰库的区间（`2.5~4.0` 左右，随距离调节）。
  - 用鲁棒评估选最好。
- 若仍不行：遍历 `phi` 每 15 度尝试首碰合法球。
- 仍失败：选择“最近的目标球”做最小风险击打，并做鲁棒检查。

若安全球的最佳得分仍低于防守底线（`SAFE_SHOT_THRESHOLD=-50`），则尝试 `_try_kick_shot()`：

- Kick Shot：对合法首碰的目标球用较大力度（`V0=5.0~6.5`）+ 小角度扰动制造复杂局面，但仍用鲁棒评估筛掉致命错误。
- Bank Shot：朝袋口方向加大角度偏移（约 ±15~25 度）以确保碰库，尝试通过反弹解决卡球。

---

## 11. 超参数与工程取舍（可写进报告）

- `SIMULATION_TIMEOUT=2s`：单次仿真超时保护（平台相关）。
- `ROBUSTNESS_SAMPLES_FINAL=10` / `ROBUSTNESS_SAMPLES_SCREEN=4`：鲁棒评估采样数（最终/筛选），越大越稳但越慢。
- `ROBUST_TOPK=6`：只对 Top-K 候选做 FINAL 评估，控制总仿真预算。
- `SIMULATION_COUNT=30`：局部微调次数，越大越可能找到更优解但越慢。
- 综合权重：`0.3*geo + 0.7*sim`：强调“仿真 + 鲁棒”才决定最终。

**优点**：几乎不依赖训练；对规则犯规的抑制强，实战胜率常高。

**缺点**：推理时间随仿真次数增长；评分函数/阈值较启发式；超时机制在 Windows 上不可用（若评测系统为 Linux 则无影响）。
